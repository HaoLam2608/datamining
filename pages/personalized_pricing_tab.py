import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
import uuid

# H√†m gi·∫£ l·∫≠p CUSTOMER_ID d·ª±a tr√™n d·ªØ li·ªáu giao d·ªãch
def generate_customer_ids(df, n_customers=100):
    """T·∫°o CUSTOMER_ID gi·∫£ l·∫≠p d·ª±a tr√™n m·∫´u giao d·ªãch."""
    np.random.seed(42)
    # Gi·∫£ ƒë·ªãnh s·ªë l∆∞·ª£ng kh√°ch h√†ng l√† n_customers
    customer_ids = [str(uuid.uuid4())[:8] for _ in range(n_customers)]
    # Ph√¢n b·ªï ng·∫´u nhi√™n CUSTOMER_ID cho c√°c giao d·ªãch
    df['CUSTOMER_ID'] = np.random.choice(customer_ids, size=len(df))
    return df

# H√†m t√≠nh ƒë·ªô co gi√£n gi√° cho t·ª´ng nh√≥m kh√°ch h√†ng
def calculate_elasticity(df, group_col, price_col='PRICE', qty_col='QUANTITY'):
    """T√≠nh ƒë·ªô co gi√£n gi√° trung b√¨nh cho t·ª´ng nh√≥m."""
    elasticity_dict = {}
    for group in df[group_col].unique():
        df_group = df[df[group_col] == group].groupby(price_col)[qty_col].sum().reset_index()
        if len(df_group) > 1:
            X = df_group[[price_col]].values
            y = df_group[qty_col].values
            model = LinearRegression().fit(X, y)
            avg_price = df_group[price_col].mean()
            avg_qty = df_group[qty_col].mean()
            elasticity = abs(model.coef_[0] * (avg_price / avg_qty)) if avg_qty > 0 else 0
            elasticity_dict[group] = elasticity
        else:
            elasticity_dict[group] = None
    return elasticity_dict

# Tab 11: ƒê·ªãnh gi√° c√° nh√¢n h√≥a
def render_personalized_pricing_tab(merged, df_clean, poly_features, poly_model):
    st.header("üë§ ƒê·ªãnh gi√° c√° nh√¢n h√≥a")

    # Ki·ªÉm tra xem c√≥ c·ªôt CUSTOMER_ID ch∆∞a
    possible_customer_cols = ['CUSTOMER_ID', 'CustomerID', 'customer_id', 'UserID', 'ClientID', 'user_id']
    customer_col = None
    for col in possible_customer_cols:
        if col in merged.columns:
            customer_col = col
            break

    if not customer_col:
        st.info("Kh√¥ng t√¨m th·∫•y c·ªôt CUSTOMER_ID. ƒêang gi·∫£ l·∫≠p d·ªØ li·ªáu kh√°ch h√†ng...")
        # Gi·∫£ l·∫≠p CUSTOMER_ID
        merged = generate_customer_ids(merged.copy())
        customer_col = 'CUSTOMER_ID'
    else:
        st.success(f"ƒê√£ t√¨m th·∫•y c·ªôt: {customer_col}")

    # Ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng
    try:
        customer_analysis = merged.groupby(customer_col).agg({
            'PRICE': 'mean',
            'QUANTITY': 'sum',
            'CALENDAR_DATE': 'count',
            'ITEM_NAME': 'nunique'
        }).reset_index()
        customer_analysis = customer_analysis.rename(columns={
            'PRICE': 'Gi√° trung b√¨nh',
            'QUANTITY': 'T·ªïng s·ªë l∆∞·ª£ng',
            'CALENDAR_DATE': 'S·ªë giao d·ªãch',
            'ITEM_NAME': 'S·ªë s·∫£n ph·∫©m kh√°c nhau'
        })
        customer_analysis['Doanh thu'] = customer_analysis['Gi√° trung b√¨nh'] * customer_analysis['T·ªïng s·ªë l∆∞·ª£ng']

        # Hi·ªÉn th·ªã d·ªØ li·ªáu kh√°ch h√†ng
        st.subheader("Ph√¢n t√≠ch h√†nh vi kh√°ch h√†ng")
        st.dataframe(customer_analysis.head(10))

        # Ph√¢n kh√∫c kh√°ch h√†ng b·∫±ng KMeans
        st.subheader("Ph√¢n kh√∫c kh√°ch h√†ng")
        n_clusters = st.slider("S·ªë nh√≥m kh√°ch h√†ng", 2, 5, 3, help="Ch·ªçn s·ªë l∆∞·ª£ng nh√≥m ƒë·ªÉ ph√¢n kh√∫c kh√°ch h√†ng")
        features = customer_analysis[['Gi√° trung b√¨nh', 'T·ªïng s·ªë l∆∞·ª£ng', 'S·ªë giao d·ªãch', 'S·ªë s·∫£n ph·∫©m kh√°c nhau']].fillna(0)
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        customer_analysis['Nh√≥m'] = kmeans.fit_predict(features).astype(str)

        # Hi·ªÉn th·ªã ƒë·∫∑c ƒëi·ªÉm t·ª´ng nh√≥m
        group_summary = customer_analysis.groupby('Nh√≥m').agg({
            'Gi√° trung b√¨nh': 'mean',
            'T·ªïng s·ªë l∆∞·ª£ng': 'mean',
            'S·ªë giao d·ªãch': 'mean',
            'S·ªë s·∫£n ph·∫©m kh√°c nhau': 'mean',
            'Doanh thu': 'mean',
            customer_col: 'count'
        }).reset_index()
        group_summary = group_summary.rename(columns={customer_col: 'S·ªë kh√°ch h√†ng'})
        st.dataframe(group_summary)

        # T√≠nh ƒë·ªô co gi√£n gi√° cho t·ª´ng nh√≥m
        merged_with_groups = merged.merge(customer_analysis[[customer_col, 'Nh√≥m']], on=customer_col)
        elasticity_dict = calculate_elasticity(merged_with_groups, 'Nh√≥m')
        group_summary['ƒê·ªô co gi√£n gi√°'] = group_summary['Nh√≥m'].map(elasticity_dict)

        # ƒê·ªÅ xu·∫•t gi√° c√° nh√¢n h√≥a
        st.subheader("ƒê·ªÅ xu·∫•t gi√° c√° nh√¢n h√≥a")
        base_price = df_clean['PRICE'].mean()
        recommendations = []
        for _, row in group_summary.iterrows():
            group = row['Nh√≥m']
            elasticity = row['ƒê·ªô co gi√£n gi√°']
            avg_price = row['Gi√° trung b√¨nh']
            avg_qty = row['T·ªïng s·ªë l∆∞·ª£ng'] / row['S·ªë kh√°ch h√†ng']
            if elasticity is None:
                recommendation = "Gi·ªØ nguy√™n gi√°"
                new_price = base_price
            elif elasticity > 1:  # C·∫ßu co gi√£n
                recommendation = f"Gi·∫£m gi√° ~5-10% (co gi√£n cao: {elasticity:.2f})"
                new_price = base_price * 0.925  # Gi·∫£m 7.5%
            elif elasticity < 0.5:  # C·∫ßu k√©m co gi√£n
                recommendation = f"TƒÉng gi√° ~5-10% (co gi√£n th·∫•p: {elasticity:.2f})"
                new_price = base_price * 1.075  # TƒÉng 7.5%
            else:
                recommendation = f"Gi·ªØ nguy√™n ho·∫∑c ƒëi·ªÅu ch·ªânh nh·∫π (co gi√£n trung b√¨nh: {elasticity:.2f})"
                new_price = base_price

            # D·ª± ƒëo√°n doanh thu v·ªõi gi√° m·ªõi
            new_price_poly = poly_features.transform(np.array([[new_price]]))
            new_qty = max(0, poly_model.predict(new_price_poly)[0])
            new_revenue = new_price * new_qty
            current_revenue = avg_price * avg_qty
            revenue_change = ((new_revenue - current_revenue) / current_revenue * 100) if current_revenue > 0 else 0

            recommendations.append({
                'Nh√≥m': group,
                'S·ªë kh√°ch h√†ng': row['S·ªë kh√°ch h√†ng'],
                'ƒê·ªô co gi√£n gi√°': elasticity if elasticity is not None else 'N/A',
                'Gi√° hi·ªán t·∫°i': round(avg_price, 2),
                'Gi√° ƒë·ªÅ xu·∫•t': round(new_price, 2),
                'Doanh thu d·ª± ƒëo√°n': round(new_revenue, 2),
                'Thay ƒë·ªïi doanh thu (%)': round(revenue_change, 2),
                'ƒê·ªÅ xu·∫•t': recommendation
            })

        recommendations_df = pd.DataFrame(recommendations)
        st.dataframe(recommendations_df)

        # Bi·ªÉu ƒë·ªì so s√°nh gi√° hi·ªán t·∫°i v√† gi√° ƒë·ªÅ xu·∫•t
        melted_df = recommendations_df.melt(
            id_vars=['Nh√≥m'],
            value_vars=['Gi√° hi·ªán t·∫°i', 'Gi√° ƒë·ªÅ xu·∫•t'],
            var_name='Lo·∫°i gi√°',
            value_name='Gi√°'
        )
        chart = alt.Chart(melted_df).mark_bar().encode(
            x=alt.X('Nh√≥m:N', title='Nh√≥m kh√°ch h√†ng'),
            y=alt.Y('Gi√°:Q', title='Gi√°'),
            color=alt.Color('Lo·∫°i gi√°:N', title='Lo·∫°i gi√°'),
            xOffset='Lo·∫°i gi√°:N',
            tooltip=['Nh√≥m', 'Lo·∫°i gi√°', 'Gi√°']
        ).properties(
            title='So s√°nh gi√° hi·ªán t·∫°i v√† gi√° ƒë·ªÅ xu·∫•t theo nh√≥m'
        )
        st.altair_chart(chart, use_container_width=True)

        # ƒê·ªÅ xu·∫•t chi·∫øn l∆∞·ª£c
        st.subheader("Chi·∫øn l∆∞·ª£c ƒë·ªãnh gi√° c√° nh√¢n h√≥a")
        for _, row in recommendations_df.iterrows():
            st.write(f"**Nh√≥m {row['Nh√≥m']}** ({row['S·ªë kh√°ch h√†ng']} kh√°ch h√†ng): {row['ƒê·ªÅ xu·∫•t']}")
            st.write(f"- Gi√° ƒë·ªÅ xu·∫•t: {row['Gi√° ƒë·ªÅ xu·∫•t']:.2f} (Doanh thu d·ª± ƒëo√°n: {row['Doanh thu d·ª± ƒëo√°n']:.2f}, thay ƒë·ªïi: {row['Thay ƒë·ªïi doanh thu (%)']:.2f}%)")

    except Exception as e:
        st.error(f"L·ªói khi ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng: {e}")