import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression
import uuid

# H√†m gi·∫£ l·∫≠p CUSTOMER_ID
def generate_customer_ids(df, n_customers=100):
    """T·∫°o CUSTOMER_ID gi·∫£ l·∫≠p d·ª±a tr√™n m·∫´u giao d·ªãch."""
    np.random.seed(42)
    customer_ids = [str(uuid.uuid4())[:8] for _ in range(n_customers)]
    df['CUSTOMER_ID'] = np.random.choice(customer_ids, size=len(df))
    return df

# H√†m t√≠nh ƒë·ªô co gi√£n gi√°
def calculate_elasticity(df, group_col, price_col='PRICE', qty_col='QUANTITY'):
    """T√≠nh ƒë·ªô co gi√£n gi√° trung b√¨nh cho t·ª´ng nh√≥m."""
    elasticity_dict = {}
    for group in df[group_col].unique():
        df_group = df[df[group_col] == group].dropna(subset=[price_col, qty_col])
        if len(df_group[price_col].unique()) > 1:
            X = df_group[[price_col]].values
            y = df_group[qty_col].values
            poly = PolynomialFeatures(degree=2)
            X_poly = poly.fit_transform(X)
            model = LinearRegression().fit(X_poly, y)
            avg_price = df_group[price_col].mean()
            pred_qty = model.predict(poly.transform([[avg_price]]))[0]
            coef = model.coef_[1] + 2 * model.coef_[2] * avg_price  # ƒê·∫°o h√†m ƒëa th·ª©c b·∫≠c 2
            elasticity = abs(coef * avg_price / pred_qty) if pred_qty != 0 else 0
            elasticity = min(elasticity, 5.0)  # Gi·ªõi h·∫°n t·ªëi ƒëa l√† 5
            elasticity_dict[group] = elasticity
        else:
            elasticity_dict[group] = None
    return elasticity_dict

# H√†m ph√¢n t√≠ch v√† ƒë·ªãnh gi√° c√° nh√¢n h√≥a
def analyze_personalized_pricing(df_clean):
    st.header("üë§ Ph√¢n t√≠ch v√† ƒë·ªãnh gi√° c√° nh√¢n h√≥a")
    
    # Ki·ªÉm tra c·ªôt CUSTOMER_ID
    possible_customer_cols = ['CUSTOMER_ID', 'CustomerID', 'customer_id', 'UserID', 'ClientID', 'user_id']
    customer_col = None
    for col in possible_customer_cols:
        if col in df_clean.columns:
            customer_col = col
            break
    
    if not customer_col:
        with st.spinner("Kh√¥ng t√¨m th·∫•y c·ªôt CUSTOMER_ID. ƒêang gi·∫£ l·∫≠p d·ªØ li·ªáu kh√°ch h√†ng..."):
            df_clean = generate_customer_ids(df_clean.copy())
            customer_col = 'CUSTOMER_ID'
            st.info("ƒê√£ t·∫°o CUSTOMER_ID gi·∫£ l·∫≠p cho ph√¢n t√≠ch")
    else:
        st.success(f"ƒê√£ t√¨m th·∫•y c·ªôt: {customer_col}")
    
    # X√¢y d·ª±ng m√¥ h√¨nh ƒëa th·ª©c cho d·ª± ƒëo√°n s·ªë l∆∞·ª£ng
    df_for_model = df_clean[['PRICE', 'QUANTITY']].dropna()
    X = df_for_model[['PRICE']].values
    y = df_for_model['QUANTITY'].values
    poly = PolynomialFeatures(degree=2)
    X_poly = poly.fit_transform(X)
    poly_model = LinearRegression().fit(X_poly, y)
    
    # Ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng
    try:
        # T·ªïng quan d·ªØ li·ªáu
        st.subheader("T·ªïng quan d·ªØ li·ªáu")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("T·ªïng s·ªë kh√°ch h√†ng", df_clean[customer_col].nunique())
        col2.metric("T·ªïng s·ªë giao d·ªãch", len(df_clean))
        col3.metric("Gi√° trung b√¨nh", f"{df_clean['PRICE'].mean():.2f}")
        col4.metric("T·ªïng doanh thu", f"{(df_clean['PRICE'] * df_clean['QUANTITY']).sum():.2f}")
        
        # Ph√¢n t√≠ch h√†nh vi kh√°ch h√†ng
        customer_analysis = df_clean.groupby(customer_col).agg({
            'PRICE': 'mean',
            'QUANTITY': 'sum',
            'CALENDAR_DATE': 'count',
            'ITEM_NAME': 'nunique'
        }).reset_index()
        customer_analysis = customer_analysis.rename(columns={
            'PRICE': 'Gi√° trung b√¨nh',
            'QUANTITY': 'T·ªïng s·ªë l∆∞·ª£ng',
            'CALENDAR_DATE': 'S·ªë giao d·ªãch',
            'ITEM_NAME': 'S·ªë s·∫£n ph·∫©m kh√°c nhau'
        })
        customer_analysis['Doanh thu'] = customer_analysis['Gi√° trung b√¨nh'] * customer_analysis['T·ªïng s·ªë l∆∞·ª£ng']
        
        st.subheader("Ph√¢n t√≠ch h√†nh vi kh√°ch h√†ng")
        st.dataframe(customer_analysis.head(10), use_container_width=True)
        
        # Ph√¢n kh√∫c kh√°ch h√†ng
        st.subheader("Ph√¢n kh√∫c kh√°ch h√†ng")
        n_clusters = st.slider("S·ªë nh√≥m kh√°ch h√†ng", 2, 5, 3, help="Ch·ªçn s·ªë l∆∞·ª£ng nh√≥m ƒë·ªÉ ph√¢n kh√∫c kh√°ch h√†ng")
        
        features = customer_analysis[['Gi√° trung b√¨nh', 'T·ªïng s·ªë l∆∞·ª£ng', 'S·ªë giao d·ªãch', 'Doanh thu']].fillna(0)
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        with st.spinner("ƒêang ph√¢n kh√∫c kh√°ch h√†ng..."):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(features_scaled)
        
        # T·∫°o t√™n nh√≥m d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm
        group_summary = customer_analysis.groupby(cluster_labels).agg({
            'Gi√° trung b√¨nh': 'mean',
            'T·ªïng s·ªë l∆∞·ª£ng': 'mean',
            'S·ªë giao d·ªãch': 'mean',
            'S·ªë s·∫£n ph·∫©m kh√°c nhau': 'mean',
            'Doanh thu': 'mean',
            customer_col: 'count'
        }).reset_index()
        group_summary = group_summary.rename(columns={customer_col: 'S·ªë kh√°ch h√†ng', 'index': 'Cluster'})
        
        # T√≠nh trung b√¨nh to√†n b·ªô ƒë·ªÉ so s√°nh
        overall_means = customer_analysis[['Gi√° trung b√¨nh', 'T·ªïng s·ªë l∆∞·ª£ng', 'S·ªë giao d·ªãch', 'Doanh thu']].mean()
        
        # G√°n t√™n nh√≥m b·∫±ng ti·∫øng Vi·ªát
        group_names = []
        for idx, row in group_summary.iterrows():
            price = row['Gi√° trung b√¨nh']
            qty = row['T·ªïng s·ªë l∆∞·ª£ng']
            freq = row['S·ªë giao d·ªãch']
            revenue = row['Doanh thu']
            
            is_high_price = price > overall_means['Gi√° trung b√¨nh'] * 1.1
            is_low_price = price < overall_means['Gi√° trung b√¨nh'] * 0.9
            is_high_qty = qty > overall_means['T·ªïng s·ªë l∆∞·ª£ng'] * 1.1
            is_low_qty = qty < overall_means['T·ªïng s·ªë l∆∞·ª£ng'] * 0.9
            is_high_freq = freq > overall_means['S·ªë giao d·ªãch'] * 1.1
            is_low_freq = freq < overall_means['S·ªë giao d·ªãch'] * 0.9
            is_high_revenue = revenue > overall_means['Doanh thu'] * 1.1
            is_low_revenue = revenue < overall_means['Doanh thu'] * 0.9
            
            if is_high_price and is_high_revenue and not is_low_qty:
                name = "Kh√°ch H√†ng Cao C·∫•p Trung Th√†nh"
            elif is_low_price and is_high_qty:
                name = "Kh√°ch H√†ng Nh·∫°y C·∫£m Gi√° Mua S·ªë L∆∞·ª£ng L·ªõn"
            elif is_low_qty and is_low_freq:
                name = "Kh√°ch H√†ng Th·ªânh Tho·∫£ng Chi Ti√™u Th·∫•p"
            elif is_high_freq and not is_low_revenue:
                name = "Kh√°ch H√†ng Th∆∞·ªùng Xuy√™n Mua S·∫Øm ƒê·ªÅu ƒê·∫∑n"
            else:
                name = "Kh√°ch H√†ng C√¢n B·∫±ng C·∫•p Trung"
            group_names.append(name)
        
        cluster_to_name = {str(i): name for i, name in enumerate(group_names)}
        customer_analysis['Nh√≥m'] = [cluster_to_name[str(label)] for label in cluster_labels]
        group_summary['Nh√≥m'] = group_names
        
        st.dataframe(group_summary.drop(columns=['Cluster']).style.background_gradient(cmap='Blues'), use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì ph√¢n kh√∫c
        st.subheader("Bi·ªÉu ƒë·ªì ph√¢n kh√∫c kh√°ch h√†ng")
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox("Tr·ª•c X", ['Gi√° trung b√¨nh', 'T·ªïng s·ªë l∆∞·ª£ng', 'S·ªë giao d·ªãch', 'Doanh thu'], index=0)
        with col2:
            y_axis = st.selectbox("Tr·ª•c Y", ['Gi√° trung b√¨nh', 'T·ªïng s·ªë l∆∞·ª£ng', 'S·ªë giao d·ªãch', 'Doanh thu'], index=1)
        
        scatter_chart = alt.Chart(customer_analysis).mark_circle(size=60).encode(
            x=alt.X(x_axis, title=x_axis),
            y=alt.Y(y_axis, title=y_axis),
            color=alt.Color('Nh√≥m:N', title='Nh√≥m kh√°ch h√†ng'),
            tooltip=[customer_col, 'Nh√≥m', x_axis, y_axis, 'Doanh thu']
        ).properties(
            title=f'Ph√¢n kh√∫c kh√°ch h√†ng theo {x_axis} v√† {y_axis}',
            width=600,
            height=400
        ).interactive()
        
        st.altair_chart(scatter_chart, use_container_width=True)
        
        # ƒê·ªô co gi√£n gi√°
        merged_with_groups = df_clean.merge(customer_analysis[[customer_col, 'Nh√≥m']], on=customer_col, how='left')
        elasticity_dict = calculate_elasticity(merged_with_groups, 'Nh√≥m')
        group_summary['ƒê·ªô co gi√£n gi√°'] = group_summary['Nh√≥m'].map(elasticity_dict)
        
        # ƒê·ªÅ xu·∫•t gi√° c√° nh√¢n h√≥a
        st.subheader("ƒê·ªÅ xu·∫•t gi√° c√° nh√¢n h√≥a")
        
        recommendations = []
        damping_factor = 0.5  # H·ªá s·ªë gi·∫£m t√°c ƒë·ªông c·ªßa ƒë·ªô co gi√£n
        max_qty_change = 0.5  # Gi·ªõi h·∫°n thay ƒë·ªïi s·ªë l∆∞·ª£ng t·ªëi ƒëa 50%
        
        for _, row in group_summary.iterrows():
            group = row['Nh√≥m']
            elasticity = row['ƒê·ªô co gi√£n gi√°']
            current_price = row['Gi√° trung b√¨nh']
            avg_qty = row['T·ªïng s·ªë l∆∞·ª£ng']
            num_customers = row['S·ªë kh√°ch h√†ng']
            current_revenue = row['Doanh thu'] * num_customers  # Doanh thu t·ªïng hi·ªán t·∫°i
            
            if elasticity is None or pd.isna(elasticity):
                recommendation = "Gi·ªØ nguy√™n gi√° do thi·∫øu d·ªØ li·ªáu ƒë·ªô co gi√£n"
                new_price = current_price
            else:
                if elasticity > 1:
                    recommendation = f"Gi·∫£m gi√° ~5-10% (co gi√£n cao: {elasticity:.2f})"
                    new_price = current_price * 0.925  # Gi·∫£m 7.5%
                elif elasticity < 0.5:
                    recommendation = f"TƒÉng gi√° ~5-10% (co gi√£n th·∫•p: {elasticity:.2f})"
                    new_price = current_price * 1.075  # TƒÉng 7.5%
                else:
                    recommendation = f"Gi·ªØ nguy√™n ho·∫∑c ƒëi·ªÅu ch·ªânh nh·∫π (co gi√£n trung b√¨nh: {elasticity:.2f})"
                    new_price = current_price
            
            # D·ª± ƒëo√°n s·ªë l∆∞·ª£ng m·ªõi d·ª±a tr√™n ƒë·ªô co gi√£n
            price_change = (new_price - current_price) / current_price if current_price > 0 else 0
            qty_change = elasticity * price_change * damping_factor
            qty_change = max(min(qty_change, max_qty_change), -max_qty_change)  # Gi·ªõi h·∫°n thay ƒë·ªïi s·ªë l∆∞·ª£ng
            predicted_qty = avg_qty * (1 + qty_change) if elasticity is not None else avg_qty
            predicted_qty = max(0, predicted_qty)  # ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng kh√¥ng √¢m
            
            # T√≠nh doanh thu d·ª± ƒëo√°n cho to√†n nh√≥m
            predicted_revenue = new_price * predicted_qty * num_customers
            revenue_change = ((predicted_revenue - current_revenue) / current_revenue * 100) if current_revenue > 0 else 0
            
            recommendations.append({
                'Nh√≥m': group,
                'S·ªë kh√°ch h√†ng': num_customers,
                'ƒê·ªô co gi√£n gi√°': elasticity if elasticity is not None and not pd.isna(elasticity) else 'N/A',
                'Gi√° hi·ªán t·∫°i': round(current_price, 2),
                'Gi√° ƒë·ªÅ xu·∫•t': round(new_price, 2),
                'Doanh thu d·ª± ƒëo√°n': round(predicted_revenue, 2),
                'Thay ƒë·ªïi doanh thu (%)': round(revenue_change, 2),
                'ƒê·ªÅ xu·∫•t': recommendation
            })
        
        recommendations_df = pd.DataFrame(recommendations)
        st.dataframe(recommendations_df.style.highlight_max(axis=0, subset=['Thay ƒë·ªïi doanh thu (%)']), use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì gi√°
        melted_df = recommendations_df.melt(
            id_vars=['Nh√≥m'],
            value_vars=['Gi√° hi·ªán t·∫°i', 'Gi√° ƒë·ªÅ xu·∫•t'],
            var_name='Lo·∫°i gi√°',
            value_name='Gi√°'
        )
        chart = alt.Chart(melted_df).mark_bar().encode(
            x=alt.X('Nh√≥m:N', title='Nh√≥m kh√°ch h√†ng'),
            y=alt.Y('Gi√°:Q', title='Gi√°'),
            color=alt.Color('Lo·∫°i gi√°:N', title='Lo·∫°i gi√°'),
            xOffset='Lo·∫°i gi√°:N',
            tooltip=['Nh√≥m', 'Lo·∫°i gi√°', 'Gi√°']
        ).properties(
            title='So s√°nh gi√° hi·ªán t·∫°i v√† gi√° ƒë·ªÅ xu·∫•t theo nh√≥m',
            width=600,
            height=400
        )
        st.altair_chart(chart, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì doanh thu
        revenue_chart = alt.Chart(recommendations_df).mark_bar().encode(
            x=alt.X('Nh√≥m:N', title='Nh√≥m kh√°ch h√†ng'),
            y=alt.Y('Thay ƒë·ªïi doanh thu (%):Q', title='Thay ƒë·ªïi doanh thu (%)'),
            color=alt.condition(
                alt.datum['Thay ƒë·ªïi doanh thu (%)'] > 0,
                alt.value('green'),
                alt.value('red')
            ),
            tooltip=['Nh√≥m', 'Thay ƒë·ªïi doanh thu (%)', 'Gi√° ƒë·ªÅ xu·∫•t', 'Doanh thu d·ª± ƒëo√°n']
        ).properties(
            title='D·ª± ƒëo√°n thay ƒë·ªïi doanh thu theo nh√≥m',
            width=600,
            height=400
        )
        st.altair_chart(revenue_chart, use_container_width=True)
        
        # ƒê·ªÅ xu·∫•t chi·∫øn l∆∞·ª£c
        st.subheader("Chi·∫øn l∆∞·ª£c ƒë·ªãnh gi√° c√° nh√¢n h√≥a")
        st.write("D·ª±a tr√™n ph√¢n t√≠ch ƒë·ªô co gi√£n gi√° c·ªßa t·ª´ng ph√¢n kh√∫c kh√°ch h√†ng, ch√∫ng t√¥i ƒë·ªÅ xu·∫•t:")
        
        for _, row in recommendations_df.iterrows():
            with st.expander(f"{row['Nh√≥m']} ({row['S·ªë kh√°ch h√†ng']} kh√°ch h√†ng)"):
                st.write(f"**ƒê·ªÅ xu·∫•t:** {row['ƒê·ªÅ xu·∫•t']}")
                st.write(f"- Gi√° hi·ªán t·∫°i: {row['Gi√° hi·ªán t·∫°i']:.2f}")
                st.write(f"- Gi√° ƒë·ªÅ xu·∫•t: {row['Gi√° ƒë·ªÅ xu·∫•t']:.2f}")
                st.write(f"- Doanh thu d·ª± ƒëo√°n: {row['Doanh thu d·ª± ƒëo√°n']:.2f}")
                st.write(f"- Thay ƒë·ªïi doanh thu: {row['Thay ƒë·ªïi doanh thu (%)']:.2f}%")
                
                if row['ƒê·ªô co gi√£n gi√°'] == 'N/A' or pd.isna(row['ƒê·ªô co gi√£n gi√°']):
                    st.write("**Chi·∫øn l∆∞·ª£c marketing:** Thu th·∫≠p th√™m d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch ƒë·ªô co gi√£n gi√°")
                elif row['ƒê·ªô co gi√£n gi√°'] > 1:
                    st.write("**Chi·∫øn l∆∞·ª£c marketing:** Nh√≥m n√†y nh·∫°y c·∫£m v·ªõi gi√°. N√™n t·∫≠p trung v√†o c√°c ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i, gi·∫£m gi√° theo s·ªë l∆∞·ª£ng, ho·∫∑c g√≥i combo ti·∫øt ki·ªám.")
                elif row['ƒê·ªô co gi√£n gi√°'] < 0.5:
                    st.write("**Chi·∫øn l∆∞·ª£c marketing:** Nh√≥m n√†y √≠t nh·∫°y c·∫£m v·ªõi gi√°. N√™n t·∫≠p trung v√†o ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m, d·ªãch v·ª• kh√°ch h√†ng, v√† tr·∫£i nghi·ªám cao c·∫•p.")
                else:
                    st.write("**Chi·∫øn l∆∞·ª£c marketing:** Nh√≥m c√≥ ƒë·ªô nh·∫°y c·∫£m gi√° trung b√¨nh. C√¢n b·∫±ng gi·ªØa y·∫øu t·ªë gi√° v√† gi√° tr·ªã cung c·∫•p.")
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh ph√¢n t√≠ch: {e}")
        return

# H√†m ch√≠nh
def render_personalized_pricing_tab():
    with st.sidebar:
        st.header("H∆∞·ªõng d·∫´n")
        st.markdown("""
        - T·∫£i l√™n file customer_data.csv.
        - File ph·∫£i ch·ª©a c√°c c·ªôt: CUSTOMER_ID, ITEM_NAME, PRICE, QUANTITY, CALENDAR_DATE.
        - Xem k·∫øt qu·∫£ ph√¢n kh√∫c kh√°ch h√†ng v√† ƒë·ªÅ xu·∫•t gi√° c√° nh√¢n h√≥a.
        """)
    
    # T·∫£i file customer_data
    st.subheader("T·∫£i l√™n d·ªØ li·ªáu")
    customer_file = st.file_uploader("T·∫£i l√™n customer_data.csv", type=["csv"])
    
    if not customer_file:
        st.warning("Vui l√≤ng t·∫£i l√™n file customer_data.csv ƒë·ªÉ ti·∫øp t·ª•c.")
        return
    
    try:
        # ƒê·ªçc file
        df_clean = pd.read_csv(customer_file)
        
        # Chu·∫©n h√≥a t√™n c·ªôt
        df_clean.columns = df_clean.columns.str.strip().str.upper()
        
        # ƒê·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt
        required_columns = ['CUSTOMER_ID', 'ITEM_NAME', 'PRICE', 'QUANTITY', 'CALENDAR_DATE']
        if not all(col in df_clean.columns for col in required_columns):
            st.error("File customer_data.csv ph·∫£i ch·ª©a c√°c c·ªôt: CUSTOMER_ID, ITEM_NAME, PRICE, QUANTITY, CALENDAR_DATE.")
            return
        
        # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
        df_clean['CALENDAR_DATE'] = pd.to_datetime(df_clean['CALENDAR_DATE'], errors='coerce')
        df_clean['PRICE'] = pd.to_numeric(df_clean['PRICE'], errors='coerce')
        df_clean['QUANTITY'] = pd.to_numeric(df_clean['QUANTITY'], errors='coerce')
        
        # L√†m s·∫°ch d·ªØ li·ªáu
        df_clean = df_clean.dropna(subset=['PRICE', 'QUANTITY', 'CALENDAR_DATE', 'ITEM_NAME'])
        df_clean = df_clean[df_clean['PRICE'] > 0]
        df_clean = df_clean[df_clean['QUANTITY'] > 0]
        
        if df_clean.empty:
            st.warning("D·ªØ li·ªáu sau khi l√†m s·∫°ch r·ªóng. Vui l√≤ng ki·ªÉm tra file ƒë·∫ßu v√†o.")
            return
        
        # G·ªçi h√†m ph√¢n t√≠ch
        analyze_personalized_pricing(df_clean)
        
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi ƒë·ªçc v√† x·ª≠ l√Ω file: {e}")
        return